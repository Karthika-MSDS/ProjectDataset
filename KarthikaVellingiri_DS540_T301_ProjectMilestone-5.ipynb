{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ef078016-69f3-40d2-aa9a-71d03e8a9dc8",
   "metadata": {},
   "source": [
    "<center>\n",
    "\n",
    "## Term Project: Analysing Trends in Movie Performance and Ratings\n",
    "### Milestone 5: Merging the Data and Storing in a Database/Visualizing Data\n",
    "### Karthika Vellingiri\n",
    "### 15 Nov 2024\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7f74719-8a7e-41c9-942c-9324dd418682",
   "metadata": {},
   "source": [
    "### Milestone 2: Cleaning/Formatting Flat File Source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c53a2e86-2eb5-4adc-9e8b-a9c37e5dd36a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import ast\n",
    "import re\n",
    "from fuzzywuzzy import fuzz\n",
    "import langcodes  # Import the langcodes library to handle language codes\n",
    "import warnings\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "# Suppress warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "\n",
    "# Step #1: Load the dataset\n",
    "df = pd.read_csv(\"movies_metadata.csv\", low_memory=False)  # Load the movie metadata CSV file\n",
    "print(f\"Data file 'movies_metadata.csv' loaded successfully.\\n\")\n",
    "\n",
    "print(\"Starting Data cleanup...\")  # Indicate that data cleanup is starting\n",
    "\n",
    "# Step #2: Drop specified columns that are not needed for analysis\n",
    "columns_to_drop = ['adult', 'belongs_to_collection', 'homepage', 'overview', 'poster_path', 'tagline', 'video']\n",
    "df = df.drop(columns=columns_to_drop, errors='ignore')  # Drop columns, ignore errors if columns are missing\n",
    "\n",
    "# Step #3: Remove duplicate rows from the dataset\n",
    "initial_row_count = df.shape[0]  # Store initial row count for reference\n",
    "df = df.drop_duplicates()  # Remove duplicate entries\n",
    "\n",
    "# Step #4: Remove rows with specific criteria that do not meet quality standards\n",
    "df = df[\n",
    "    (df['genres'].apply(lambda x: bool(ast.literal_eval(x)) if pd.notnull(x) else False)) &  # Check if genres are valid\n",
    "    (df['production_companies'].apply(lambda x: bool(ast.literal_eval(x)) if pd.notnull(x) else False)) &  # Check production companies\n",
    "    (df['production_countries'].apply(lambda x: bool(ast.literal_eval(x)) if pd.notnull(x) else False)) &  # Check production countries\n",
    "    (df['spoken_languages'].apply(lambda x: bool(ast.literal_eval(x)) if pd.notnull(x) else False)) &  # Check spoken languages\n",
    "    (df['imdb_id'].notna()) &  # Ensure IMDb ID is present\n",
    "    (df['imdb_id'] != '') &  # Ensure IMDb ID is not empty\n",
    "    (df['original_language'].notna()) &  # Ensure original language is present\n",
    "    (df['original_language'] != '') &  # Ensure original language is not empty\n",
    "    (df['revenue'].notna()) &  # Ensure revenue is present\n",
    "    (df['revenue'] != 0) &  # Ensure revenue is greater than zero\n",
    "    (df['popularity'] != 0)  # Ensure popularity is greater than zero\n",
    "]\n",
    "\n",
    "# Step #5: Filter 'original_title' and 'title' to remove entries with junk values and numbers\n",
    "#df = df[~df['original_title'].str.contains(r'[^\\x00-\\x7F]|[0-9]', regex=True)]  # Remove titles with non-ASCII characters or numbers\n",
    "df = df[~(df['original_title'].str.contains(r'[0-9:&a-z]', regex=True) | df['title'].str.contains(r'[0-9:&a-z]', regex=True))]\n",
    "\n",
    "\n",
    "# Step #6: Validate 'production_companies' for proper names and IDs\n",
    "df = df[df['production_companies'].apply(lambda x: all(\n",
    "    isinstance(company.get('name', ''), str) and company.get('name') and isinstance(company.get('id', 0), int)\n",
    "    for company in ast.literal_eval(x)) if pd.notnull(x) else False)]  # Ensure each company has a valid name and ID\n",
    "\n",
    "# Step #7: Validate 'production_countries' for proper ISO codes and names\n",
    "df = df[df['production_countries'].apply(lambda x: all(\n",
    "    isinstance(country.get('iso_3166_1', ''), str) and len(country.get('iso_3166_1')) == 2 and\n",
    "    isinstance(country.get('name', ''), str) and country.get('name')\n",
    "    for country in ast.literal_eval(x)) if pd.notnull(x) else False)]  # Ensure each country has valid ISO codes and names\n",
    "\n",
    "# Step #8: Remove rows with inappropriate revenue values (less than 10,000)\n",
    "df = df[df['revenue'] > 10000]  # Filter out low-revenue entries\n",
    "\n",
    "# Step #9: Remove rows with inappropriate budget values (less than 50,000)\n",
    "df['budget'] = pd.to_numeric(df['budget'], errors='coerce')  # Convert budget to numeric, coerce errors to NaN\n",
    "df = df[df['budget'] > 50000]  # Filter out low-budget entries\n",
    "\n",
    "# Step #10: Handle 'runtime' column for missing values\n",
    "avg_runtime = 90  # Define average runtime to use for filtering\n",
    "df['runtime'] = df['runtime'].apply(lambda x: avg_runtime if pd.isnull(x) else x)  # Fill missing runtime with average value\n",
    "\n",
    "# Remove rows with runtime less than 90 minutes and greater than 180 minutes\n",
    "df = df[(df['runtime'] >= 90) & (df['runtime'] <= 180)]  # Filter for valid runtime entries\n",
    "\n",
    "# Step #11: Derive 'genres' from the dataset\n",
    "def derive_genres(genres):\n",
    "    \"\"\"Extracts genre names from the JSON-like structure in the 'genres' column.\"\"\"\n",
    "    if pd.isnull(genres):  # Check for null values\n",
    "        return \"\"\n",
    "    try:\n",
    "        genre_list = ast.literal_eval(genres)  # Convert string to list\n",
    "        return \", \".join([genre['name'] for genre in genre_list])  # Return a comma-separated string of genre names\n",
    "    except (ValueError, SyntaxError):  # Handle potential parsing errors\n",
    "        return \"\"\n",
    "\n",
    "df['genres'] = df['genres'].apply(derive_genres)  # Apply the genre extraction function\n",
    "\n",
    "# Step #12: Create multigenre column to indicate if multiple genres are present\n",
    "def check_multigenre(genres):\n",
    "    \"\"\"Check if a movie has multiple genres.\"\"\"\n",
    "    if pd.isnull(genres) or genres == \"\":  # Check for null or empty genres\n",
    "        return \"no\"  # Return \"no\" if no genres are present\n",
    "    genre_list = [genre.strip() for genre in genres.split(\",\")]  # Split genres into a list\n",
    "    return \"yes\" if len(genre_list) > 1 else \"no\"  # Return \"yes\" if multiple genres exist\n",
    "\n",
    "df['multigenre'] = df['genres'].apply(check_multigenre)  # Apply the multigenre check\n",
    "\n",
    "# Step #13: Process spoken languages to create multilanguage column\n",
    "def process_spoken_languages(languages):\n",
    "    \"\"\"Convert spoken languages data into a comma-separated string and check if multiple languages exist.\"\"\"\n",
    "    if pd.isnull(languages):  # Check for null languages\n",
    "        return \"\", \"no\"  # Return empty string and \"no\"\n",
    "    \n",
    "    language_list = [language['iso_639_1'] for language in ast.literal_eval(languages)]  # Extract ISO language codes\n",
    "    \n",
    "    # Use langcodes to map language codes to names\n",
    "    mapped_languages = [langcodes.Language.get(lang_code).language_name() for lang_code in language_list]\n",
    "    \n",
    "    # Filter out any that didn't map successfully\n",
    "    cleaned_languages = [lang for lang in mapped_languages if lang]  # Keep only successfully mapped languages\n",
    "    \n",
    "    multilanguage = \"yes\" if len(cleaned_languages) > 1 else \"no\"  # Check if there are multiple languages\n",
    "    return \", \".join(cleaned_languages), multilanguage  # Return cleaned languages and multilanguage indicator\n",
    "\n",
    "# Apply the process_spoken_languages function to the spoken_languages column\n",
    "df[['spoken_languages', 'multilanguage']] = df['spoken_languages'].apply(lambda x: pd.Series(process_spoken_languages(x)))\n",
    "\n",
    "# Step #14: Process production companies to create multicompany column\n",
    "def process_production_companies(companies):\n",
    "    \"\"\"Convert production companies data into a comma-separated string and check if multiple companies exist.\"\"\"\n",
    "    if pd.isnull(companies):  # Check for null companies\n",
    "        return \"\", \"no\"  # Return empty string and \"no\"\n",
    "    \n",
    "    company_list = [company['name'] for company in ast.literal_eval(companies)]  # Extract company names\n",
    "    multicompany = \"yes\" if len(company_list) > 1 else \"no\"  # Check if there are multiple companies\n",
    "    return \", \".join(company_list), multicompany  # Return company names and multicompany indicator\n",
    "\n",
    "# Apply the process_production_companies function to the production_companies column\n",
    "df[['production_companies', 'multicompany']] = df['production_companies'].apply(lambda x: pd.Series(process_production_companies(x)))\n",
    "\n",
    "# Step #15: Process production countries to create multicountry column\n",
    "def process_production_countries(countries):\n",
    "    \"\"\"Convert production countries data into a comma-separated string and check if multiple countries exist.\"\"\"\n",
    "    if pd.isnull(countries):  # Check for null countries\n",
    "        return \"\", \"no\"  # Return empty string and \"no\"\n",
    "    \n",
    "    country_list = [country['name'] for country in ast.literal_eval(countries)]  # Extract country names\n",
    "    multicountry = \"yes\" if len(country_list) > 1 else \"no\"  # Check if there are multiple countries\n",
    "    return \", \".join(country_list), multicountry  # Return country names and multicountry indicator\n",
    "\n",
    "# Apply the process_production_countries function to the production_countries column\n",
    "df[['production_countries', 'multicountry']] = df['production_countries'].apply(lambda x: pd.Series(process_production_countries(x)))\n",
    "\n",
    "# Step #16: Fuzzy match 'original_title' and 'title' to ensure they are similar\n",
    "df = df[df.apply(lambda row: fuzz.ratio(row['original_title'], row['title']) > 80, axis=1)]  # Keep only rows with high similarity\n",
    "\n",
    "# Step #17: Filter 'status' column for only \"Released\" status\n",
    "df = df[df['status'] == 'Released']  # Retain only movies that have been released\n",
    "\n",
    "# Step #18: Filter 'vote_average' and 'vote_count' columns for appropriate values\n",
    "df = df[~((df['vote_average'] < 5.0) & (df['vote_count'] < 100))]  # Exclude low-rated and low-vote movies\n",
    "\n",
    "# Step #19: Validate Data Types\n",
    "def validate_data_types(df):\n",
    "    \"\"\"Check if numeric columns are indeed numeric and categorical columns are strings.\"\"\"\n",
    "    expected_types = {\n",
    "        'budget': 'numeric',\n",
    "        'revenue': 'numeric',\n",
    "        'runtime': 'numeric',\n",
    "        'vote_average': 'numeric',\n",
    "        'vote_count': 'numeric',\n",
    "        'original_language': 'string',\n",
    "        'status': 'string',\n",
    "        'imdb_id': 'string'\n",
    "    }\n",
    "    \n",
    "    for column, expected_type in expected_types.items():\n",
    "        if expected_type == 'numeric' and not pd.api.types.is_numeric_dtype(df[column]):\n",
    "            print(f\"Warning: {column} is not numeric!\")  # Alert if column is not numeric\n",
    "        elif expected_type == 'string' and not pd.api.types.is_string_dtype(df[column]):\n",
    "            print(f\"Warning: {column} is not a string!\")  # Alert if column is not string\n",
    "\n",
    "validate_data_types(df)  # Validate the data types of the DataFrame\n",
    "\n",
    "# Step #20: Convert 'popularity' to numeric, forcing errors to NaN\n",
    "df['popularity'] = pd.to_numeric(df['popularity'], errors='coerce')  # Convert popularity to numeric\n",
    "\n",
    "# Step #21: Round off popularity to 2 decimal points\n",
    "df['popularity'] = df['popularity'].round(2)  # Round popularity to 2 decimal points\n",
    "\n",
    "# Step #22: Format revenue and budget in dollars\n",
    "df['revenue'] = df['revenue'].apply(lambda x: f\"${x:,.2f}\")  # Format revenue with dollar sign and commas\n",
    "df['budget'] = df['budget'].apply(lambda x: f\"${x:,.2f}\")  # Format budget with dollar sign and commas\n",
    "\n",
    "# Step #23: Remove decimal from vote count\n",
    "df['vote_count'] = df['vote_count'].astype(int)  # Convert vote count to integer to remove decimals\n",
    "\n",
    "# Step #24: Convert column names to lowercase for consistency\n",
    "df.columns = [col.lower() for col in df.columns]  # Change all column names to lowercase\n",
    "\n",
    "# Indicate the completion of data cleanup\n",
    "print(\"Data cleanup completed successfully!!!\")  # Notify that the cleanup process has finished\n",
    "\n",
    "# Step #25: Rename runtime column and remove decimal\n",
    "df.rename(columns={'runtime': 'runtime(in_minutes)'}, inplace=True)  # Rename runtime column\n",
    "df['runtime(in_minutes)'] = df['runtime(in_minutes)'].astype(int)  # Convert to integer to remove decimals\n",
    "\n",
    "# Step #26: Print dataset before and after cleanup for comparison\n",
    "display(HTML(\"<br><center><h3><strong>Dataset before cleanup</h3></strong></center>\"))\n",
    "\n",
    "initial_df = pd.read_csv(\"movies_metadata.csv\", low_memory=False)  # Load the original dataset again for comparison\n",
    "display(HTML(initial_df.head().to_html(index=False)))  # Display the first few rows of the original dataset\n",
    "\n",
    "display(HTML(\"<br><center><strong><h3>Dataset after cleanup</h3></strong></center>\"))\n",
    "display(HTML(df.head().to_html(index=False)))  # Display the first few rows of the cleaned dataset\n",
    "\n",
    "# Save the cleaned dataset to a new CSV file\n",
    "cleaned_file = \"cleaned_movies_metadata.csv\"  # Define the output file path\n",
    "df.to_csv(cleaned_file, index=False)  # Save the cleaned DataFrame to CSV\n",
    "print(f\"Cleaned dataset saved to {cleaned_file}.\\n\")  # Notify that the cleaned dataset has been saved\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "353d36ab-27e0-41ca-b564-df922685cc28",
   "metadata": {},
   "source": [
    "### Milestone 3: Cleaning/Formatting Website Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c138c0bd-4a45-4c34-ab9e-04bc4f0b92a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup  # Import BeautifulSoup for HTML parsing\n",
    "import pandas as pd  # Import pandas for data manipulation\n",
    "import requests  # Import requests to make HTTP requests\n",
    "from IPython.display import display, HTML  # Import display functions for HTML output\n",
    "\n",
    "# Function to extract data for a given year\n",
    "def extract_data(year):\n",
    "    url = f\"https://www.boxofficemojo.com/year/world/{year}/\"  # Construct URL with the year\n",
    "    response = requests.get(url)  # Send a request to the URL\n",
    "    soup = BeautifulSoup(response.text, \"html.parser\")  # Parse the HTML content\n",
    "    \n",
    "    # Find the table with movie data on the page\n",
    "    table = soup.find(\"table\")\n",
    "    if table is None:  # If no table is found, return an empty DataFrame\n",
    "        return pd.DataFrame()\n",
    "    \n",
    "    rows = table.find_all(\"tr\")  # Find all rows in the table\n",
    "    \n",
    "    # Extract column headers from the first row (header row)\n",
    "    headers = [header.text.strip() for header in rows[0].find_all(\"th\")]\n",
    "    \n",
    "    # Extract data from each row after the header row\n",
    "    data = []\n",
    "    for row in rows[1:]:\n",
    "        cols = row.find_all(\"td\")  # Find all columns in each row\n",
    "        cols = [col.text.strip() for col in cols]  # Strip whitespace from each cell\n",
    "        data.append(cols)  # Append row data to the data list\n",
    "    \n",
    "    # Create a DataFrame from the extracted data and add 'Year' column\n",
    "    df = pd.DataFrame(data, columns=headers)\n",
    "    df['Year'] = year  # Add the year to the DataFrame\n",
    "    return df  # Return the DataFrame for the year\n",
    "\n",
    "# Step 1: Loop through years and extract data\n",
    "print(\"Starting Data Extraction . . .\")  # Initial message\n",
    "all_data = []  # Initialize list to store all years' data\n",
    "for i, year in enumerate(range(1977, 2021), start=1):  # Loop through years 1977 to 2020\n",
    "    year_data = extract_data(year)  # Call function to extract data for the year\n",
    "    all_data.append(year_data)  # Append the DataFrame to all_data\n",
    "    if year != 2020:\n",
    "        print(f\"Data Extraction completed for the year {year}...\", end='\\r')  # Print message for each year, replacing in-place\n",
    "    else:\n",
    "        print(\"Data Extraction completed Successfully ! ! ! \", flush=True)  # Print completion message for the last year\n",
    "\n",
    "# Step 2: Combine all data into a single DataFrame\n",
    "combined_df = pd.concat(all_data, ignore_index=True)  # Concatenate all DataFrames into one large DataFrame\n",
    "# Copy combined_df to original_df, excluding the 'Year' column to have the exact table content\n",
    "original_df = combined_df.drop(columns=['Year']).copy()  # Drop 'Year' and create a copy for comparison\n",
    "\n",
    "# Step 3: Sort combined DataFrame by 'Worldwide' before cleaning\n",
    "combined_df['Worldwide'] = combined_df['Worldwide'].replace({'\\$': '', ',': ''}, regex=True).astype(float)  # Remove dollar signs and commas, convert to float for sorting\n",
    "combined_df = combined_df.sort_values(by='Worldwide', ascending=False).reset_index(drop=True)  # Sort by Worldwide revenue\n",
    "\n",
    "# Step 4: Trim whitespace from all cells\n",
    "combined_df = combined_df.apply(lambda x: x.str.strip() if x.dtype == \"object\" else x)  # Strip whitespace from string columns\n",
    "\n",
    "# Step 5: Replace empty strings with NaN values\n",
    "combined_df = combined_df.replace('', pd.NA)  # Replace any empty strings with NaN\n",
    "\n",
    "# Step 6: Convert 'Worldwide' and 'Domestic' columns to numeric by removing currency symbols and commas\n",
    "combined_df['Worldwide_numeric'] = combined_df['Worldwide'].replace({'\\$': '', ',': '', '-': '0'}, regex=True).astype(float)  # Remove symbols, commas, convert to float\n",
    "combined_df['Domestic_numeric'] = combined_df['Domestic'].replace({'\\$': '', ',': '', '-': '0'}, regex=True).astype(float)  # Same for Domestic column\n",
    "\n",
    "# Step 7: Derive 'Foreign' and 'Foreign %' columns\n",
    "combined_df['Foreign'] = combined_df['Worldwide_numeric'] - combined_df['Domestic_numeric']  # Calculate Foreign revenue as Worldwide - Domestic\n",
    "combined_df['Foreign %'] = round((combined_df['Foreign'] / combined_df['Worldwide_numeric']) * 100, 2)  # Calculate Foreign percentage\n",
    "\n",
    "# Step 8: Derive 'Domestic %' column\n",
    "combined_df['Domestic %'] = round((combined_df['Domestic_numeric'] / combined_df['Worldwide_numeric']) * 100, 2)  # Calculate Domestic percentage\n",
    "\n",
    "# Step 9: Format the 'Domestic %' column to display as a percentage\n",
    "combined_df['Domestic %'] = combined_df['Domestic %'].astype(str) + '%'  # Append '%' symbol to Domestic percentage\n",
    "\n",
    "# Step 10: Format monetary columns to display as currency\n",
    "combined_df['Worldwide'] = combined_df['Worldwide_numeric'].apply(lambda x: f\"${round(x):,d}\" if pd.notnull(x) else x)  # Format Worldwide as currency\n",
    "combined_df['Domestic'] = combined_df['Domestic_numeric'].apply(lambda x: f\"${round(x):,d}\" if pd.notnull(x) else x)  # Format Domestic as currency\n",
    "combined_df['Foreign'] = combined_df['Foreign'].apply(lambda x: f\"${round(x):,d}\" if pd.notnull(x) else x)  # Format Foreign as currency\n",
    "\n",
    "# Step 11: Remove records where 'Domestic_numeric' is 0\n",
    "combined_df = combined_df[combined_df['Domestic_numeric'] != 0]  # Filter out records with zero Domestic revenue\n",
    "\n",
    "# Step 12: Drop the 'Rank' column if it exists\n",
    "if 'Rank' in combined_df.columns:\n",
    "    combined_df = combined_df.drop(columns=['Rank'])  # Drop Rank column if present\n",
    "\n",
    "# Step 13: Remove duplicates based on 'Release Group'\n",
    "# Convert 'Release Group' to lowercase for case-insensitive duplicate removal\n",
    "combined_df['Release Group_lower'] = combined_df['Release Group'].str.lower()  # Convert all Release Group entries to lowercase\n",
    "\n",
    "# Remove duplicate entries based on 'Release Group', keeping the first occurrence\n",
    "combined_df = combined_df.drop_duplicates(subset=['Release Group_lower'], keep='first')  \n",
    "\n",
    "# Step 14: Rank the data by Worldwide revenue\n",
    "combined_df['Rank'] = combined_df['Worldwide_numeric'].rank(method='min', ascending=False).astype(int)  # Rank movies by Worldwide revenue\n",
    "combined_df = combined_df.sort_values(by='Rank').reset_index(drop=True)  # Sort the DataFrame by Rank\n",
    "\n",
    "# Step 15: Remove records where 'Worldwide' is not equal to 'Domestic' and 'Foreign %' is 0\n",
    "combined_df = combined_df[~((combined_df['Domestic_numeric'] == combined_df['Worldwide_numeric']) & (combined_df['Foreign %'] == 0))]  # Remove movies where Worldwide == Domestic and Foreign % is 0\n",
    "\n",
    "# Step 16: Drop the temporary numeric columns\n",
    "combined_df = combined_df.drop(columns=['Worldwide_numeric', 'Domestic_numeric', 'Release Group_lower'])  # Drop numeric columns used for calculations\n",
    "\n",
    "# Step 17: Drop the '%' column, as it is replaced by new columns\n",
    "combined_df = combined_df.drop(columns=['%'], errors='ignore')  # Drop '%' column if it exists\n",
    "\n",
    "# Step 18: Select relevant columns for final output\n",
    "columns_to_print = ['Rank', 'Release Group', 'Worldwide', 'Domestic', 'Domestic %', 'Foreign', 'Foreign %', 'Year']  # Specify the columns to display\n",
    "combined_df = combined_df[columns_to_print]  # Filter the DataFrame to keep only the selected columns\n",
    "\n",
    "# Print original data before cleaning\n",
    "display(HTML(\"<br><strong><h3>Dataset before cleanup:</h3></br></strong>\"))  # Display heading for original data\n",
    "display(HTML(original_df.head(10).to_html(index=False)))  # Display first 10 rows of the original DataFrame\n",
    "\n",
    "# Step 19: Display the cleaned dataset\n",
    "# Convert DataFrame to HTML\n",
    "html_table = combined_df.head(10).to_html(index=False)  # Convert first 10 rows of the cleaned DataFrame to HTML\n",
    "\n",
    "# Align all headers to the center\n",
    "html_table = html_table.replace('<th>', '<th style=\"text-align: center;\">')  # Align headers to center\n",
    "\n",
    "# Align all data cells to the left\n",
    "html_table = html_table.replace('<td>', '<td style=\"text-align: left;\">')  # Align data cells to the left\n",
    "\n",
    "display(HTML(\"<br><strong><h3>Dataset after cleanup:</h3></br></strong>\"))  # Display heading for cleaned data\n",
    "\n",
    "# Display the modified HTML table\n",
    "display(HTML(html_table))  # Display the cleaned DataFrame\n",
    "\n",
    "# Step 20: Save cleaned data to CSV file\n",
    "combined_df.to_csv(\"cleaned_box_office_data.csv\", index=False)  # Save the cleaned DataFrame to a CSV file\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22ea12ed-ea86-43c5-85d9-faaeebedc85e",
   "metadata": {},
   "source": [
    "### Milestone 4: Connecting to an API/Pulling in the Data and Cleaning/Formatting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35224696-defd-41a2-a30d-e44a82ff037c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests  # Importing requests library for making HTTP requests to APIs\n",
    "from tabulate import tabulate  # Importing tabulate for creating nicely formatted tables\n",
    "from IPython.display import display, HTML  # Importing display and HTML for showing HTML content in Jupyter notebooks\n",
    "import re  # Importing regular expressions for string matching and extraction\n",
    "import csv  # Importing csv for handling CSV file operations\n",
    "import json  # Importing json to read the API key from a JSON file\n",
    "\n",
    "# Step 1: Read the OMDB API key from the JSON file\n",
    "with open('OMDbAPIkey.json') as f:  # Open the JSON file containing the API key\n",
    "    api_key_data = json.load(f)  # Load the JSON data\n",
    "    api_key = api_key_data[\"OMDb_API_Key\"]  # Extract the API key\n",
    "\n",
    "# Step 2: Function to fetch movies for a specific year from the OMDB API\n",
    "def fetch_movies_for_year(year):\n",
    "    print(f\"Fetching movies for the year {year}\", end='\\r')  # Indicate progress in the console\n",
    "    url = f\"http://www.omdbapi.com/?apikey={api_key}&y={year}&s=movie\"  # Construct the API URL\n",
    "    response = requests.get(url)  # Make the GET request to the OMDB API\n",
    "    \n",
    "    if response.status_code == 200:  # Check if the response is successful\n",
    "        data = response.json()  # Parse the JSON data from the response\n",
    "        results = data.get(\"Search\", [])  # Get the list of movies found, defaulting to an empty list if none\n",
    "        return results  # Return the list of movies\n",
    "    else:\n",
    "        print(f\"Failed to fetch movies for {year}. Status code: {response.status_code}\")  # Print error if the request failed\n",
    "        return []  # Return an empty list if the fetch failed\n",
    "\n",
    "# Step 3: Function to fetch detailed movie data using its IMDB ID\n",
    "def fetch_movie_details(imdb_id):\n",
    "    url = f\"http://www.omdbapi.com/?apikey={api_key}&i={imdb_id}\"  # Construct the URL for fetching details\n",
    "    response = requests.get(url)  # Make the GET request for detailed movie data\n",
    "    if response.status_code == 200:  # Check if the response is successful\n",
    "        return response.json()  # Return the parsed JSON data\n",
    "    else:\n",
    "        print(f\"Failed to fetch details for IMDB ID: {imdb_id}. Status code: {response.status_code}\")  # Print error if the request failed\n",
    "        return None  # Return None if the fetch failed\n",
    "\n",
    "# Step 4: Function to extract wins and nominations from the awards string\n",
    "def extract_awards(awards):\n",
    "    wins, nominations = 0, 0  # Initialize wins and nominations to 0\n",
    "    # Match the pattern \"X wins\" in the awards string\n",
    "    wins_match = re.search(r'(\\d+)\\s+wins?', awards, re.IGNORECASE)\n",
    "    # Match the pattern \"X nominations\" in the awards string\n",
    "    nominations_match = re.search(r'(\\d+)\\s+nominations?', awards, re.IGNORECASE)\n",
    "    \n",
    "    if wins_match:  # If wins are found in the awards string\n",
    "        wins = int(wins_match.group(1))  # Convert the captured group to an integer\n",
    "    if nominations_match:  # If nominations are found in the awards string\n",
    "        nominations = int(nominations_match.group(1))  # Convert the captured group to an integer\n",
    "    \n",
    "    return wins, nominations  # Return the extracted wins and nominations\n",
    "\n",
    "# Step 5: List to hold all movies data\n",
    "all_movies_data = []  # Initialize an empty list to store all movie data\n",
    "\n",
    "# Step 6: Specify the years for data extraction \n",
    "years_to_fetch = list(range(1978, 2024))  # Create a list of years from 1978 to 2023\n",
    "\n",
    "print(f\"Data Extraction Initiated...\")  # Print message indicating data extraction has started\n",
    "\n",
    "# Step 7: Loop through each specified year to fetch movie data\n",
    "for idx, year in enumerate(years_to_fetch):  # Enumerate over the years for indexing\n",
    "    movies = fetch_movies_for_year(year)  # Fetch movies for the current year\n",
    "    \n",
    "    for movie in movies:  # Loop through the list of fetched movies\n",
    "        title = movie.get(\"Title\")  # Get the movie title\n",
    "        year = movie.get(\"Year\")  # Get the year of the movie\n",
    "        \n",
    "        # Check if the year contains a hyphen and extract the last part\n",
    "        if '-' in year:\n",
    "            year = year.split('-')[-1].strip()  # Split and take the last part\n",
    "        elif '–' in year:  # Handle the en-dash character\n",
    "            year = year.split('–')[-1].strip()  # Split and take the last part\n",
    "            \n",
    "        imdb_id = movie.get(\"imdbID\")  # Get the IMDB ID for detailed fetching\n",
    "        movie_type = movie.get(\"Type\")  # Get the type of the movie (e.g., movie, series)\n",
    "        \n",
    "        # Step 8: Only process if the movie type is 'movie'\n",
    "        if movie_type == \"movie\":\n",
    "            # Step 9: Fetch detailed data for each movie to get more info\n",
    "            detailed_movie_data = fetch_movie_details(imdb_id)  # Get detailed movie data\n",
    "            if detailed_movie_data:  # If detailed data is fetched successfully\n",
    "                # Step 10: Extract awards, wins, and nominations\n",
    "                awards = detailed_movie_data.get(\"Awards\", \"\")  # Get the awards string\n",
    "                wins, nominations = extract_awards(awards)  # Extract wins and nominations from awards\n",
    "                \n",
    "                # Step 11: Extract additional movie attributes\n",
    "                genres = detailed_movie_data.get(\"Genre\", \"\").split(\", \")  # Get genres and split into a list\n",
    "                languages = detailed_movie_data.get(\"Language\", \"\").split(\", \")  # Get languages and split into a list\n",
    "                countries = detailed_movie_data.get(\"Country\", \"\").split(\", \")  # Get countries and split into a list\n",
    "                productions = detailed_movie_data.get(\"Production\", \"\").split(\", \")  # Get production companies and split into a list\n",
    "\n",
    "                # Step 12: Additional fields\n",
    "                released = detailed_movie_data.get(\"Released\", \"N/A\")  # Get release date, default to \"N/A\"\n",
    "                runtime = detailed_movie_data.get(\"Runtime\", \"N/A\")  # Get runtime, default to \"N/A\"\n",
    "                \n",
    "                # Remove 'min' from runtime and convert to a usable format\n",
    "                if isinstance(runtime, str) and 'min' in runtime:\n",
    "                    runtime = runtime.replace(' min', '').strip()  # Clean up the runtime string\n",
    "                else:\n",
    "                    runtime = \"N/A\"  # Default to \"N/A\" if not a valid string\n",
    "                \n",
    "                director = detailed_movie_data.get(\"Director\", \"N/A\")  # Get director name\n",
    "                metascore = detailed_movie_data.get(\"Metascore\", \"N/A\")  # Get metascore value\n",
    "                imdb_rating = detailed_movie_data.get(\"imdbRating\", \"N/A\")  # Get IMDB rating\n",
    "                imdb_votes = detailed_movie_data.get(\"imdbVotes\", \"N/A\")  # Get number of IMDB votes\n",
    "                box_office = detailed_movie_data.get(\"BoxOffice\", \"N/A\")  # Get box office collection\n",
    "\n",
    "                # Step 13: Determine if the movie has multiple genres, languages, companies, or countries\n",
    "                multigenre = \"Yes\" if len(genres) > 1 else \"No\"  # Check for multiple genres\n",
    "                multilanguage = \"Yes\" if len(languages) > 1 else \"No\"  # Check for multiple languages\n",
    "                multicompany = \"Yes\" if len(productions) > 1 else \"No\"  # Check for multiple production companies\n",
    "                multicountry = \"Yes\" if len(countries) > 1 else \"No\"  # Check for multiple countries\n",
    "\n",
    "                # Step 14: Prepare a dictionary of all relevant movie data\n",
    "                ratings_dict = {rating['Source']: rating['Value'].split('/')[0] for rating in detailed_movie_data.get(\"Ratings\", [])}\n",
    "                imdb_rating_value = ratings_dict.get(\"Internet Movie Database\", \"N/A\")  # Get IMDB rating value\n",
    "                rotten_tomatoes_value = ratings_dict.get(\"Rotten Tomatoes\", \"N/A\")  # Get Rotten Tomatoes value\n",
    "                metacritic_value = ratings_dict.get(\"Metacritic\", \"N/A\").split('/')[0]  # Get Metacritic value\n",
    "\n",
    "                # Create a dictionary to hold all relevant movie information\n",
    "                movie_data = {\n",
    "                    \"Title\": title,  # Movie title\n",
    "                    \"Year\": year,  # Movie year\n",
    "                    \"Type\": movie_type,  # Movie type\n",
    "                    \"Released\": released,  # Release date\n",
    "                    \"Runtime(in mins)\": runtime,  # Runtime in minutes\n",
    "                    \"Genre\": \", \".join(genres),  # Joined string of genres\n",
    "                    \"Director\": director,  # Director of the movie\n",
    "                    \"Language\": \", \".join(languages),  # Joined string of languages\n",
    "                    \"Country\": \", \".join(countries),  # Joined string of countries\n",
    "                    \"Production\": \", \".join(productions),  # Joined string of production companies\n",
    "                    \"Awards\": awards,  # Awards won\n",
    "                    \"Nominations\": nominations,  # Number of nominations\n",
    "                    \"Wins\": wins,  # Number of wins\n",
    "                    \"IMDB Rating\": imdb_rating_value,  # IMDB rating value\n",
    "                    \"Rotten Tomatoes\": rotten_tomatoes_value,  # Rotten Tomatoes rating\n",
    "                    \"Metacritic\": metacritic_value,  # Metacritic rating\n",
    "                    \"Metascore\": metascore,  # Metascore value\n",
    "                    \"imdbVotes\": imdb_votes,  # Number of votes on IMDB\n",
    "                    \"BoxOffice\": box_office,  # Box office collection\n",
    "                    \"Multigenre\": multigenre,  # Indicator for multiple genres\n",
    "                    \"Multilanguage\": multilanguage,  # Indicator for multiple languages\n",
    "                    \"Multicompany\": multicompany,  # Indicator for multiple production companies\n",
    "                    \"Multicountry\": multicountry,  # Indicator for multiple countries\n",
    "                }\n",
    "                all_movies_data.append(movie_data)  # Append the movie data dictionary to the list\n",
    "\n",
    "    # Step 15: Print message for each year after fetching\n",
    "    if idx < len(years_to_fetch) - 1:  # If not the last year\n",
    "        print(f\"Data Extraction completed for the year {year}...\", end='\\r')  # Indicate year completion\n",
    "    else:  # If it is the last year\n",
    "        print(\"Data Extraction completed Successfully ! ! ! \", flush=True)  # Indicate overall completion\n",
    "\n",
    "# Step 16: Prepare table headers for the CSV and display\n",
    "headers = [\"Title\", \"Year\", \"Type\", \"Released\", \"Runtime(in mins)\", \"Genre\", \"Director\", \"Language\", \"Country\", \"Production\", \"Awards\", \"Nominations\", \"Wins\", \"IMDB Rating\", \"Rotten Tomatoes\", \"Metacritic\", \"Metascore\", \"imdbVotes\", \"BoxOffice\", \"Multigenre\", \"Multilanguage\", \"Multicompany\", \"Multicountry\"]\n",
    "\n",
    "# Step 17: Create a CSV file to store the movie data\n",
    "output_file = \"formatted_API_data.csv\"  # Define the name of the output CSV file\n",
    "\n",
    "with open(output_file, 'w', newline='', encoding='utf-8') as csvfile:  # Open the CSV file for writing\n",
    "    writer = csv.DictWriter(csvfile, fieldnames=headers)  # Create a CSV writer object with the defined headers\n",
    "    writer.writeheader()  # Write the headers to the CSV file\n",
    "    writer.writerows(all_movies_data)  # Write all movie data to the CSV file\n",
    "\n",
    "# Step 18: Display Sample response in original format\n",
    "display(HTML(\"<br><strong><h3>Sample API Data(unformatted):</h3> For 1 movie:</br></strong>\"))  # Display a heading for clarity\n",
    "\n",
    "# Define the movie title for which to fetch details\n",
    "movie_title = \"Gatchaman The Movie\"  # Specify the movie title\n",
    "url = f\"http://www.omdbapi.com/?apikey={api_key}&t={movie_title}\"  # Construct the URL for fetching a specific movie\n",
    "response = requests.get(url)  # Make the GET request for the specific movie\n",
    "\n",
    "# Check if the request was successful\n",
    "if response.status_code == 200:  # If successful\n",
    "    movie_data = response.json()  # Parse the JSON response\n",
    "    print(movie_data)  # Print the JSON response to the console\n",
    "\n",
    "# Step 19: Display formatted API data\n",
    "display(HTML(\"<br><strong><h3>Formatted API Data:</h3></br></strong>\"))  # Display a heading for clarity\n",
    "\n",
    "# Convert to HTML table for display in the notebook\n",
    "rows_for_display = [[movie[header] for header in headers] for movie in all_movies_data[:5]]  # Get first 5 entries for display\n",
    "\n",
    "# Create an HTML table from the movie data using tabulate\n",
    "html_table_display = tabulate(rows_for_display, headers=headers, tablefmt=\"html\")\n",
    "\n",
    "# Display the formatted table in the notebook\n",
    "display(HTML(html_table_display))  # Render the HTML table in the notebook\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
